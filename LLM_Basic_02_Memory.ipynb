{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install langchain\n","!pip install langchain-community\n","!pip install openai"],"metadata":{"id":"PuXfcEQMl39s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('AI_KEY')"],"metadata":{"id":"Vu1ZCQUxl0Cl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 메모리 모듈의 종류\n","\n","ConversationBufferMemory             \n","ConversationBufferWindowMemory    \n","ConversationTokenBufferMemory        \n","ConversationSummaryMemory           "],"metadata":{"id":"EVQ5BvyslgtS"}},{"cell_type":"markdown","source":["## 1. ConversationBufferMemory    \n","\n","- 이전 대화의 내용을 일정한 용량만큼(buffer) 기억해주는 모듈"],"metadata":{"id":"-5miTThUltys"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"id":"2JMIKRVSloEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm_model = 'gpt-3.5-turbo-0301'\n","#llm을 정의\n","llm = ChatOpenAI(temperature=0.1, model=llm_model)\n","\n","#대화한 내역을 기억하는 역할\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(\n","    llm = llm,\n","    memory= memory,\n","\n","    #동작하는 과정을 상세히 보여줄 지 여부\n","    verbose = True\n",")"],"metadata":{"id":"QoVQK4lAlhkm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi, my name is jeongeun\")"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"PtUodWtnp4Tg","executionInfo":{"status":"ok","timestamp":1722594878477,"user_tz":-540,"elapsed":789,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"1aa17751-b718-41cb-8328-20d477314c89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi, my name is jeongeun\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Hello jeongeun, it's nice to meet you! My name is AI. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["conversation.predict(input=\"What is 2 * 4?\")"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"AUqEGbShp985","executionInfo":{"status":"ok","timestamp":1722594931052,"user_tz":-540,"elapsed":819,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"6653bed3-c4d2-477b-c27c-6786d8037886"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is jeongeun\n","AI: Hello jeongeun, it's nice to meet you! My name is AI. How can I assist you today?\n","Human: What is 2 * 4?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'2 multiplied by 4 is equal to 8.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["memory.buffer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"C846YjNPqKx-","executionInfo":{"status":"ok","timestamp":1722594982180,"user_tz":-540,"elapsed":336,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"c55f6f24-4944-402e-c380-c81a3f36e3b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Human: Hi, my name is jeongeun\\nAI: Hello jeongeun, it's nice to meet you! My name is AI. How can I assist you today?\\nHuman: What is 2 * 4?\\nAI: 2 multiplied by 4 is equal to 8.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#기억 조작 : 우리가 나누지 않은 대화의 내용을 save_context라는 함수를 통해 전달\n","memory = ConversationBufferMemory()\n","memory.save_context({\"input\" : \"Hi\"},\n","    {\"outputs\" : \"What's up?\"})"],"metadata":{"id":"j7l7ZMZEqXXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhRiAZh-q3xx","executionInfo":{"status":"ok","timestamp":1722595127093,"user_tz":-540,"elapsed":326,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"c79de789-09bd-4d15-d45c-6779b24044a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi\n","AI: What's up?\n"]}]},{"cell_type":"markdown","source":["### 2. conversationBufferWindowMemory"],"metadata":{"id":"yunXfh8qrT5Z"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory"],"metadata":{"id":"Dgk7-OTmrW9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#k의 크기에 따라, 기억하는 대화의 크기가 변화됨\n","memory = ConversationBufferWindowMemory(k=2)"],"metadata":{"id":"BMDwU9DTrcCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory.save_context({\"input\" : \"Hi\"},\n","    {\"outputs\" : \"What's up?\"})\n","memory.save_context({\"input\" : \"I'm good. How are you?\"},\n","    {\"outputs\" : \"Not bad\"})"],"metadata":{"id":"OdPizR00q6wh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OprDWxarwBw","executionInfo":{"status":"ok","timestamp":1722595396412,"user_tz":-540,"elapsed":7,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"e6a0d140-a3de-476f-ebae-c7f89af9c835"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi\n","AI: What's up?\n","Human: I'm good. How are you?\n","AI: Not bad\n"]}]},{"cell_type":"markdown","source":["### 3. conversationTokenBufferMemory     \n","\n","- 토큰을 저장하도록 하는 메모리     \n","- LLM 사용 비용에 영향을 미치는(토큰으로 사용량 계산) 토큰을 얼마만큼 저장할건지 컨트롤 할 수 있게 하여, 비용 절감에 활용할 수 있음\n"],"metadata":{"id":"k61SCQTbsE7P"}},{"cell_type":"code","source":["#랭체인, llm에서 토큰을 다루는 라이브러리\n","!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rscUBWBvsj6W","executionInfo":{"status":"ok","timestamp":1722595589340,"user_tz":-540,"elapsed":4666,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"317a2af5-e274-44b8-a370-8b159135e462"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.7.0\n"]}]},{"cell_type":"code","source":["from langchain.memory import ConversationTokenBufferMemory\n","from langchain.llms import OpenAI\n","\n","#\"gpt-3.5-turbo-0301\" : 응답해주는 llm모델의 버전\n","llm = ChatOpenAI(temperature=0.1, model=\"gpt-3.5-turbo-0301\")"],"metadata":{"id":"AqfZBVtysqjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#옵션\n","#llm = 어떤 llm인가\n","#max_token_limit ===== 얼마만큼의 토큰을 기억할거냐?\n","memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n","\n","memory.save_context({\"input\" : \"Hi\"},\n","    {\"outputs\" : \"What's up?\"})\n","memory.save_context({\"input\" : \"I'm good. How are you?\"},\n","    {\"outputs\" : \"Not bad\"})\n","memory.save_context({\"input\" : \"I like reading books.\"},\n","    {\"outputs\" : \"That's sounds interesting\"})"],"metadata":{"id":"67K1dj0LsILw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory.buffer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"RBtxDgL-tiLd","executionInfo":{"status":"ok","timestamp":1722595869621,"user_tz":-540,"elapsed":324,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"44304c77-3666-4085-a9d6-32a028e57bde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Human: I'm good. How are you?\\nAI: Not bad\\nHuman: I like reading books.\\nAI: That's sounds interesting\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["### 4. ConversationSummaryMemory     \n","\n","- 지금까지의 대화 내용을 \"요약\"해서 기억하도록 함"],"metadata":{"id":"wJHDUx5Ct9XC"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryMemory"],"metadata":{"id":"D1OyCTZ5uFJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a long string\n","schedule = \"There is a meeting at 8am with your product team. \\\n","You will need your powerpoint presentation prepared. \\\n","9am-12pm have time to work on your LangChain \\\n","project which will go quickly because Langchain is such a powerful tool. \\\n","At Noon, lunch at the italian resturant with a customer who is driving \\\n","from over an hour away to meet you to understand the latest in AI. \\\n","Be sure to bring your laptop to show the latest LLM demo.\""],"metadata":{"id":"Y1b8NJAauVsT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory = ConversationSummaryMemory(llm=llm, max_token_limit=500)\n","\n","memory.save_context({\"input\" : \"Hi\"},\n","    {\"outputs\" : \"What's up?\"})\n","memory.save_context({\"input\" : \"I'm good. How are you?\"},\n","    {\"outputs\" : \"Not bad\"})\n","memory.save_context({\"input\" : \"What's the schedule today?\"},\n","                    {\"output\": f\"{schedule}\"})"],"metadata":{"id":"kJAKQJoNtwC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory.buffer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"39pqDMG9wXbM","executionInfo":{"status":"ok","timestamp":1722596562080,"user_tz":-540,"elapsed":318,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"c34c9261-67e2-44c2-ad22-bb289e37e97a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The AI greets the human and provides a detailed schedule for the day, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in the latest in AI. The human asks about what is needed for a good demo show, and the AI explains that it requires a clear understanding of the audience and their needs, a well-prepared and rehearsed presentation, a clear and concise message, visual aids, and a thorough knowledge of the product or service. The human then asks about the requirements for the 8:00 am meeting with the product team, and the AI suggests bringing notes, relevant documents, and having a clear agenda and goals for the meeting.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n","conversation.predict(input=\"What is needed for meeting at 8:00 am?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"bKU6DqnBu76i","executionInfo":{"status":"ok","timestamp":1722596514876,"user_tz":-540,"elapsed":2493,"user":{"displayName":"seonwoo park","userId":"02798799167365351101"}},"outputId":"8f4a232e-a938-43f4-c25d-02fd79ef5024"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","The AI greets the human and provides a detailed schedule for the day, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in the latest in AI. The human asks about what is needed for a good demo show, and the AI explains that it requires a clear understanding of the audience and their needs, a well-prepared and rehearsed presentation, a clear and concise message, visual aids, and a thorough knowledge of the product or service.\n","Human: What is needed for meeting at 8:00 am?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'The meeting with the product team at 8:00 am will require you to bring your notes and any relevant documents or materials related to the project. It may also be helpful to have a clear agenda and goals for the meeting.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]}]}